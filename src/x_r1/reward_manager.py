# Wrapper for accuracy reward functions
# Use data source to determine which accuracy reward function to use
# Please import the reward function in the reward_score folder
# and add a new elif statement here
def accuracy_reward(prompts=None, completions=None, **reward_kwargs):
    """
    This function is used to manage the accuracy rewards for the model based on the data source.
    
    Args:
        prompts: The prompts provided to the model
        completions: The completions generated by the model
        data_source: The source of the data, used to determine which reward function to use
        **reward_kwargs: Additional keyword arguments to pass to the reward function
        
    Returns:
        A reward function or a list of reward values depending on the data source
    """    
    # Create a dictionary of kwargs for each completion, excluding data_source
    other_kwargs_list = [
        {k: v[i] for k, v in reward_kwargs.items() if k != "data_source"}
        for i in range(len(completions))
    ]
    
    # Calculate rewards for each completion based on the data source
    # TODO: may parallelize this using multiprocessing for code execution or multithreading for LLM judge
    rewards = []
    for prompt, completion, data_source, kwargs in zip(prompts, completions, reward_kwargs["data_source"], other_kwargs_list):
        if data_source == "x-r1":
            from src.x_r1.reward_score.xr1 import accuracy_answer_reward
            reward = accuracy_answer_reward(completion=completion, **kwargs)
        # TODO: add more data sources
        elif data_source == "gsm8k":
            from src.x_r1.reward_score.gsm8k import compute_score
            reward = compute_score(solution_str=completion, **kwargs)
        elif data_source == "bigcodebench":
            from src.x_r1.reward_score.bigcodebench import compute_score
            reward = compute_score(solution_str=completion[0]['content'], ground_truth=kwargs["reward_model"]["ground_truth"])
        elif data_source == "codeforce":
            from src.x_r1.reward_score.codeforce import compute_score
            reward = compute_score(solution_str=completion[0]['content'], ground_truth=kwargs["reward_model"]["ground_truth"])
        elif data_source == "coder1":
            from src.x_r1.reward_score.coder1 import compute_score
            reward = compute_score(solution_str=completion, ground_truth=kwargs["reward_model"]["ground_truth"], extra_info=kwargs["extra_info"])
        elif data_source == "deepscaler":
            from src.x_r1.reward_score.deepscaler import deepscaler_reward_fn
            reward = deepscaler_reward_fn(solution_str=completion, ground_truth=kwargs["reward_model"]["ground_truth"], enable_llm=False)
        else:
            raise ValueError(f"Data source {data_source} not supported")
        rewards.append(reward)
    return rewards